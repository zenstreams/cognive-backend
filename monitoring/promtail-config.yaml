# Promtail Configuration for Cognive Control Plane
# Collects logs from Docker containers and ships to Loki

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push
    tenant_id: cognive
    batchwait: 1s
    batchsize: 1048576
    timeout: 10s

scrape_configs:
  # Docker container logs
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    relabel_configs:
      # Keep only containers from cognive project
      - source_labels: ['__meta_docker_container_label_com_docker_compose_project']
        regex: cognive.*
        action: keep
      
      # Use container name as job label
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'
      
      # Use service name from compose
      - source_labels: ['__meta_docker_container_label_com_docker_compose_service']
        target_label: 'service'
      
      # Add environment label
      - source_labels: ['__meta_docker_container_label_environment']
        target_label: 'environment'
    
    pipeline_stages:
      # Parse JSON logs from FastAPI
      - json:
          expressions:
            level: level
            message: message
            timestamp: timestamp
            logger: name
            request_id: request_id
            user_id: user_id
            agent_id: agent_id
            run_id: run_id
      
      # Set log level as label
      - labels:
          level:
          logger:
      
      # Extract timestamp
      - timestamp:
          source: timestamp
          format: RFC3339Nano
          fallback_formats:
            - RFC3339
            - "2006-01-02T15:04:05.999999999Z07:00"
      
      # Output final log line
      - output:
          source: message

  # Cognive API logs (if mounted as volume)
  - job_name: cognive-api-files
    static_configs:
      - targets:
          - localhost
        labels:
          job: cognive-api
          service: api
          __path__: /var/log/cognive/*.log
    
    pipeline_stages:
      - json:
          expressions:
            level: level
            message: message
            timestamp: timestamp
      - labels:
          level:
      - timestamp:
          source: timestamp
          format: RFC3339Nano
      - output:
          source: message

  # PostgreSQL logs
  - job_name: postgres
    static_configs:
      - targets:
          - localhost
        labels:
          job: postgres
          service: database
          __path__: /var/log/postgresql/*.log
    
    pipeline_stages:
      - regex:
          expression: '^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d+) (?P<level>\w+)\s+(?P<message>.*)$'
      - labels:
          level:
      - timestamp:
          source: timestamp
          format: "2006-01-02 15:04:05.000"
      - output:
          source: message

  # RabbitMQ logs
  - job_name: rabbitmq
    static_configs:
      - targets:
          - localhost
        labels:
          job: rabbitmq
          service: messaging
          __path__: /var/log/rabbitmq/*.log
    
    pipeline_stages:
      - regex:
          expression: '^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d+) \[(?P<level>\w+)\] (?P<message>.*)$'
      - labels:
          level:
      - output:
          source: message

  # Celery worker logs
  - job_name: celery
    static_configs:
      - targets:
          - localhost
        labels:
          job: celery
          service: worker
          __path__: /var/log/celery/*.log
    
    pipeline_stages:
      - regex:
          expression: '^\[(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d+): (?P<level>\w+)/(?P<worker>\w+)\] (?P<message>.*)$'
      - labels:
          level:
          worker:
      - timestamp:
          source: timestamp
          format: "2006-01-02 15:04:05,000"
      - output:
          source: message

# Target sync period for discovering new log files
target_config:
  sync_period: 10s


